{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This application is a binary classification AUTO ML which runs 6 different models and chooses\n",
    "the best one based on the score picked by user. After running this program, you will get the score diagram of\n",
    "all models, ROC chart of the best model, and pickled files of all 6 models.\n",
    "## Models used in this Auto ML\n",
    "Models used in this application:\n",
    "    1- Decision Tree\n",
    "    2- Random Forest\n",
    "    3- K Nearest Neighbors\n",
    "    4- NeuralNetwork\n",
    "    5- SVM\n",
    "    6- Logistic Regression\n",
    "    \n",
    "## How to run Classification Auto ML?\n",
    "    1-  Copy all the files in this directory in your computer\n",
    "\n",
    "    2-  Initialize(edit) the config.ini with these parameters:\n",
    "\n",
    "        filename:  Full path of the input file. This app assumes that all test and training data are integrated in\n",
    "        one csv file.\n",
    "        Example: C:/Users/danta/PycharmProjects/automl_ad/diabet.csv\n",
    "\n",
    "        test_size = The size of test data you want be chooses off the whole data. This number is between 0 and 1.\n",
    "        Example: 0.25\n",
    "\n",
    "        target: The target column of your data\n",
    "        Example: class\n",
    "\n",
    "        scoring_type: The type of score you want Auto ML chooses the model based on. For this application available options\n",
    "        are: [accuracy, precision, average_precision_score, f1_score, log_loss, recall]\n",
    "        Example: accuracy\n",
    "\n",
    "    3-  Please run the \"Panel.py\" or this file \"Panel.ipynb\".\n",
    "    \n",
    "## How to add a new model to this Auto Model?\n",
    "    Please refer to help document of this application (\"help.txt\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models_List import models_dict\n",
    "from AutoModel import DataModel\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from configparser import ConfigParser\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ConfigParser()\n",
    "parser.read('config.ini')\n",
    "filename = parser.get('files', 'filename')\n",
    "test_size = eval(parser.get('model', 'test_size'))\n",
    "target = parser.get('model', 'target')\n",
    "scoring_type = parser.get('model', 'scoring_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = DataModel(filename, scoring_type, test_size=test_size, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test data by Decision Tree is: 0.5116279069767442\n",
      "Score on test data by Random Forest is: 0.576271186440678\n",
      "Score on test data by SVM is: 0.5357142857142857\n",
      "Score on test data by KNN is: 0.5538461538461538\n",
      "Score on test data by Logistic Regression is: 0.5486725663716814\n",
      "Train on 576 samples, validate on 193 samples\n",
      "Epoch 1/30\n",
      " - 1s - loss: 0.6811 - val_loss: 0.6800\n",
      "Epoch 2/30\n",
      " - 0s - loss: 0.6592 - val_loss: 0.6760\n",
      "Epoch 3/30\n",
      " - 0s - loss: 0.6504 - val_loss: 0.6570\n",
      "Epoch 4/30\n",
      " - 0s - loss: 0.6427 - val_loss: 0.6506\n",
      "Epoch 5/30\n",
      " - 0s - loss: 0.6404 - val_loss: 0.6495\n",
      "Epoch 6/30\n",
      " - 0s - loss: 0.6325 - val_loss: 0.6533\n",
      "Epoch 7/30\n",
      " - 0s - loss: 0.6290 - val_loss: 0.6464\n",
      "Epoch 8/30\n",
      " - 0s - loss: 0.6298 - val_loss: 0.6448\n",
      "Epoch 9/30\n",
      " - 0s - loss: 0.6256 - val_loss: 0.6469\n",
      "Epoch 10/30\n",
      " - 0s - loss: 0.6260 - val_loss: 0.6444\n",
      "Epoch 11/30\n",
      " - 0s - loss: 0.6141 - val_loss: 0.6333\n",
      "Epoch 12/30\n",
      " - 0s - loss: 0.6251 - val_loss: 0.6404\n",
      "Epoch 13/30\n",
      " - 0s - loss: 0.6169 - val_loss: 0.6502\n",
      "Epoch 14/30\n",
      " - 0s - loss: 0.6149 - val_loss: 0.6407\n",
      "Epoch 15/30\n",
      " - 0s - loss: 0.6081 - val_loss: 0.6331\n",
      "Epoch 16/30\n",
      " - 0s - loss: 0.6092 - val_loss: 0.6564\n",
      "Epoch 17/30\n",
      " - 0s - loss: 0.6070 - val_loss: 0.6325\n",
      "Epoch 18/30\n",
      " - 0s - loss: 0.6020 - val_loss: 0.6311\n",
      "Epoch 19/30\n",
      " - 0s - loss: 0.6033 - val_loss: 0.6268\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.6012 - val_loss: 0.6608\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.6005 - val_loss: 0.6325\n",
      "Epoch 22/30\n",
      " - 0s - loss: 0.5956 - val_loss: 0.6527\n",
      "Epoch 23/30\n",
      " - 0s - loss: 0.5948 - val_loss: 0.6253\n",
      "Epoch 24/30\n",
      " - 0s - loss: 0.5993 - val_loss: 0.6295\n",
      "Epoch 25/30\n",
      " - 0s - loss: 0.5957 - val_loss: 0.6458\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.5911 - val_loss: 0.6230\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.5936 - val_loss: 0.6212\n",
      "Epoch 28/30\n",
      " - 0s - loss: 0.5982 - val_loss: 0.6226\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.5966 - val_loss: 0.6198\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.5870 - val_loss: 0.6171\n",
      "Score on test data by SVM Tree is: 0.45217391304347826\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "models_list = []\n",
    "scores_list = []\n",
    "model_files_list = []\n",
    "\n",
    "for model_name, model in models_dict.items():\n",
    "    score, model_file = list(experiment.run(model_name, model))\n",
    "    results.append({model_name: [score, model_file]})\n",
    "    models_list.append(model_name)\n",
    "    scores_list.append(score)\n",
    "    model_files_list.append(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and show the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = max(scores_list)\n",
    "best_score_index = scores_list.index(best_score)\n",
    "best_model = models_list[best_score_index]\n",
    "best_model_file = model_files_list[best_score_index]\n",
    "y_pos = np.arange(len(models_list))\n",
    "scores = scores_list\n",
    "plt.bar(y_pos, scores_list, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, models_list)\n",
    "plt.ylabel(scoring_type)\n",
    "plt.title('Model Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.roc(best_model_file, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
